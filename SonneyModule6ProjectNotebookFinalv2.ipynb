{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork1047-2023-01-01\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n",
    "\n",
    "\n",
    "# Classification with Python\n",
    "\n",
    "\n",
    "Estimated time needed: **25** minutes\n",
    "    \n",
    "\n",
    "## Objectives\n",
    "\n",
    "After completing this lab you will be able to:\n",
    "\n",
    "* Confidently create classification models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In this notebook we try to practice all the classification algorithms that we learned in this course.\n",
    "\n",
    "We load a dataset using Pandas library, apply the following algorithms, and find the best one for this specific dataset by accuracy evaluation methods.\n",
    "\n",
    "Let's first load required libraries:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn import preprocessing\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### About dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "This dataset is about the performance of basketball teams. The __cbb.csv__ data set includes performance data about five seasons of 354 basketball teams. It includes the following fields:\n",
    "\n",
    "| Field          | Description                                                                           |\n",
    "|----------------|---------------------------------------------------------------------------------------|\n",
    "|TEAM |\tThe Division I college basketball school|\n",
    "|CONF|\tThe Athletic Conference in which the school participates in (A10 = Atlantic 10, ACC = Atlantic Coast Conference, AE = America East, Amer = American, ASun = ASUN, B10 = Big Ten, B12 = Big 12, BE = Big East, BSky = Big Sky, BSth = Big South, BW = Big West, CAA = Colonial Athletic Association, CUSA = Conference USA, Horz = Horizon League, Ivy = Ivy League, MAAC = Metro Atlantic Athletic Conference, MAC = Mid-American Conference, MEAC = Mid-Eastern Athletic Conference, MVC = Missouri Valley Conference, MWC = Mountain West, NEC = Northeast Conference, OVC = Ohio Valley Conference, P12 = Pac-12, Pat = Patriot League, SB = Sun Belt, SC = Southern Conference, SEC = South Eastern Conference, Slnd = Southland Conference, Sum = Summit League, SWAC = Southwestern Athletic Conference, WAC = Western Athletic Conference, WCC = West Coast Conference)|\n",
    "|G|\tNumber of games played|\n",
    "|W|\tNumber of games won|\n",
    "|ADJOE|\tAdjusted Offensive Efficiency (An estimate of the offensive efficiency (points scored per 100 possessions) a team would have against the average Division I defense)|\n",
    "|ADJDE|\tAdjusted Defensive Efficiency (An estimate of the defensive efficiency (points allowed per 100 possessions) a team would have against the average Division I offense)|\n",
    "|BARTHAG|\tPower Rating (Chance of beating an average Division I team)|\n",
    "|EFG_O|\tEffective Field Goal Percentage Shot|\n",
    "|EFG_D|\tEffective Field Goal Percentage Allowed|\n",
    "|TOR|\tTurnover Percentage Allowed (Turnover Rate)|\n",
    "|TORD|\tTurnover Percentage Committed (Steal Rate)|\n",
    "|ORB|\tOffensive Rebound Percentage|\n",
    "|DRB|\tDefensive Rebound Percentage|\n",
    "|FTR|\tFree Throw Rate (How often the given team shoots Free Throws)|\n",
    "|FTRD|\tFree Throw Rate Allowed|\n",
    "|2P_O|\tTwo-Point Shooting Percentage|\n",
    "|2P_D|\tTwo-Point Shooting Percentage Allowed|\n",
    "|3P_O|\tThree-Point Shooting Percentage|\n",
    "|3P_D|\tThree-Point Shooting Percentage Allowed|\n",
    "|ADJ_T|\tAdjusted Tempo (An estimate of the tempo (possessions per 40 minutes) a team would have against the team that wants to play at an average Division I tempo)|\n",
    "|WAB|\tWins Above Bubble (The bubble refers to the cut off between making the NCAA March Madness Tournament and not making it)|\n",
    "|POSTSEASON|\tRound where the given team was eliminated or where their season ended (R68 = First Four, R64 = Round of 64, R32 = Round of 32, S16 = Sweet Sixteen, E8 = Elite Eight, F4 = Final Four, 2ND = Runner-up, Champion = Winner of the NCAA March Madness Tournament for that given year)|\n",
    "|SEED|\tSeed in the NCAA March Madness Tournament|\n",
    "|YEAR|\tSeason\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Load Data From CSV File  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Let's load the dataset [NB Need to provide link to csv file]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillsNetwork/labs/Module%206/cbb.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Column\n",
    "Next we'll add a column that will contain \"true\" if the wins above bubble are over 7 and \"false\" if not. We'll call this column Win Index or \"windex\" for short. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['windex'] = np.where(df.WAB > 7, 'True', 'False')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Data visualization and pre-processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Next we'll filter the data set to the teams that made the Sweet Sixteen, the Elite Eight, and the Final Four in the post season. We'll also create a new dataframe that will hold the values with the new column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.loc[df['POSTSEASON'].str.contains('F4|S16|E8', na=False)]\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df1['POSTSEASON'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WAB is Wins Above Bubble (The bubble refers to the cut off between making the NCAA March Madness Tournament and not making it)\n",
    "# WAB ranges from -1.1 and 11.6.  With the decimals I suppose it may be the average wins above bubble in 5 seasons\n",
    "df1['WAB'].value_counts().sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.BARTHAG.min(), df1.BARTHAG.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "32 teams made it into the Sweet Sixteen, 16 into the Elite Eight, and 8 made it into the Final Four over 5 seasons. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets plot some columns to underestand the data better:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice: installing seaborn might takes a few minutes\n",
    "!conda install -c anaconda seaborn -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "bins = np.linspace(df1.BARTHAG.min(), df1.BARTHAG.max(), 10)\n",
    "g = sns.FacetGrid(df1, col=\"windex\", hue=\"POSTSEASON\", palette=\"Set1\", col_wrap=6)\n",
    "g.map(plt.hist, 'BARTHAG', bins=bins, ec=\"k\")\n",
    "\n",
    "g.axes[-1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "bins = np.linspace(df1.ADJOE.min(), df1.ADJOE.max(), 10)\n",
    "g = sns.FacetGrid(df1, col=\"windex\", hue=\"POSTSEASON\", palette=\"Set1\", col_wrap=2)\n",
    "g.map(plt.hist, 'ADJOE', bins=bins, ec=\"k\")\n",
    "\n",
    "g.axes[-1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Pre-processing:  Feature selection/extraction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Lets look at how Adjusted Defense Efficiency plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "bins = np.linspace(df1.ADJDE.min(), df1.ADJDE.max(), 10)\n",
    "g = sns.FacetGrid(df1, col=\"windex\", hue=\"POSTSEASON\", palette=\"Set1\", col_wrap=2)\n",
    "g.map(plt.hist, 'ADJDE', bins=bins, ec=\"k\")\n",
    "g.axes[-1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "We see that this data point doesn't impact the ability of a team to get into the Final Four. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Convert Categorical features to numerical values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Lets look at the postseason:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df1.groupby(['windex'])['POSTSEASON'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "13% of teams with 6 or less wins above bubble make it into the final four while 17% of teams with 7 or more do.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Lets convert wins above bubble (winindex) under 7 to 0 and over 7 to 1:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df1['windex'].replace(to_replace=['False','True'], value=[0,1],inplace=True)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Feature selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Let's define feature sets, X:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "X = df1[['G', 'W', 'ADJOE', 'ADJDE', 'BARTHAG', 'EFG_O', 'EFG_D',\n",
    "       'TOR', 'TORD', 'ORB', 'DRB', 'FTR', 'FTRD', '2P_O', '2P_D', '3P_O',\n",
    "       '3P_D', 'ADJ_T', 'WAB', 'SEED', 'windex']]\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "What are our lables? Round where the given team was eliminated or where their season ended (R68 = First Four, R64 = Round of 64, R32 = Round of 32, S16 = Sweet Sixteen, E8 = Elite Eight, F4 = Final Four, 2ND = Runner-up, Champion = Winner of the NCAA March Madness Tournament for that given year)|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "y = df1['POSTSEASON'].values\n",
    "y[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y.aggregate()\n",
    "#np.count_nonzero(y)\n",
    "unique_values, counts = np.unique(y, return_counts=True)\n",
    "\n",
    "# Print the results\n",
    "for value, count in zip(unique_values, counts):\n",
    "    print(f\"{value} occurs {count} times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Normalize Data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Data Standardization gives data zero mean and unit variance (technically should be done after train test split )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "X= preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Training and Validation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Split the data into Training and Validation data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# We split the X into train and test to find the best k\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=4)#modified from test_size=0.2 to test_size=0.3 as \n",
    "#accuracy and precision for F4 was zero with all max_depth settings\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Validation set:', X_val.shape,  y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Classification \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now, it is your turn, use the training set to build an accurate model. Then use the validation set  to report the accuracy of the model\n",
    "You should use the following algorithm:\n",
    "- K Nearest Neighbor(KNN)\n",
    "- Decision Tree\n",
    "- Support Vector Machine\n",
    "- Logistic Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbor(KNN)\n",
    "\n",
    "<b>Question  1 </b> Build a KNN model using a value of k equals five, find the accuracy on the validation data (X_val and y_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use <code> accuracy_score</cdoe>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acuracy =  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "#Question 1 Answer\n",
    "neigh = KNeighborsClassifier(n_neighbors = 5).fit(X_train,y_train)\n",
    "yhat=neigh.predict(X_val)\n",
    "mean_acc = metrics.accuracy_score(y_val, yhat)\n",
    "print('acuracy = ',mean_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Question  2</b> Determine and print the accuracy for the first 15 values of k on the validation data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with K:  1 =  0.3333333333333333\n",
      "Accuracy with K:  2 =  0.3333333333333333\n",
      "Accuracy with K:  3 =  0.5\n",
      "Accuracy with K:  4 =  0.5833333333333334\n",
      "Accuracy with K:  5 =  0.6666666666666666\n",
      "Accuracy with K:  6 =  0.5833333333333334\n",
      "Accuracy with K:  7 =  0.5833333333333334\n",
      "Accuracy with K:  8 =  0.6666666666666666\n",
      "Accuracy with K:  9 =  0.5833333333333334\n",
      "Accuracy with K:  10 =  0.5833333333333334\n",
      "Accuracy with K:  11 =  0.5833333333333334\n",
      "Accuracy with K:  12 =  0.5\n",
      "Accuracy with K:  13 =  0.5833333333333334\n",
      "Accuracy with K:  14 =  0.5833333333333334\n",
      "Accuracy with K:  15 =  0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "#Qn 2 Answer\n",
    "Ks = 16\n",
    "\n",
    "for n in range(1,Ks):\n",
    "    \n",
    "    #Train Model and Predict  \n",
    "    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)\n",
    "    yhat=neigh.predict(X_val)\n",
    "    mean_acc = metrics.accuracy_score(y_val, yhat)\n",
    "    print('Accuracy with K: ',n,'= ',mean_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines of code fit a <code>DecisionTreeClassifier</code>:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 - Answer\n",
    "#Based on accuracy it seems min value for max depth is 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Question  3</b> Determine the minumum   value for the parameter <code>max_depth</code> that improves results \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when max_depth is:  1 accuracy =  0.6666666666666666\n",
      "when max_depth is:  2 accuracy =  0.6666666666666666\n",
      "when max_depth is:  3 accuracy =  0.5\n",
      "when max_depth is:  4 accuracy =  0.3333333333333333\n",
      "when max_depth is:  5 accuracy =  0.4166666666666667\n",
      "when max_depth is:  6 accuracy =  0.5\n",
      "when max_depth is:  7 accuracy =  0.5\n",
      "when max_depth is:  8 accuracy =  0.4166666666666667\n",
      "when max_depth is:  9 accuracy =  0.4166666666666667\n",
      "when max_depth is:  10 accuracy =  0.4166666666666667\n",
      "when max_depth is:  11 accuracy =  0.4166666666666667\n",
      "when max_depth is:  12 accuracy =  0.5\n",
      "when max_depth is:  13 accuracy =  0.5\n",
      "when max_depth is:  14 accuracy =  0.4166666666666667\n",
      "when max_depth is:  15 accuracy =  0.5\n"
     ]
    }
   ],
   "source": [
    "Ks = 16\n",
    "mean_acc = np.zeros((Ks-1))\n",
    "mdepth = np.zeros((Ks-1))\n",
    "\n",
    "for n in range(1,Ks):\n",
    "    \n",
    "    #Train Model and Predict  \n",
    "    dtree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = n).fit(X_train,y_train)\n",
    "    yhat=dtree.predict(X_val)\n",
    "    mean_acc[n-1] = metrics.accuracy_score(y_val, yhat)\n",
    "    mdepth[n-1]= n\n",
    "\n",
    "    \n",
    "    \n",
    "    print('when max_depth is: ',n,'accuracy = ',mean_acc[n-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Question  4</b> Train the support  vector machine model and determine the accuracy on the validation data for each kernel. Find the kernel (linear, poly, rbf, sigmoid) that provides the best score on the validation data and train a SVM using it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Tried all 4 Kernals below.  Best score was provided by Poly kernal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when kernal is:  linear accuracy =  0.25\n",
      "when kernal is:  poly accuracy =  0.6666666666666666\n",
      "when kernal is:  rbf accuracy =  0.5833333333333334\n",
      "when kernal is:  sigmoid accuracy =  0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "Kernals=['linear', 'poly', 'rbf', 'sigmoid']\n",
    "Ks = 5\n",
    "mean_acc = np.zeros((Ks-1))\n",
    "\n",
    "\n",
    "for n in range(1,Ks):\n",
    "    \n",
    "    #Train Model and Predict  \n",
    "    \n",
    "    clf = svm.SVC(kernel=Kernals[n-1])\n",
    "    clf.fit(X_train, y_train) \n",
    "    yhat = clf.predict(X_val)\n",
    "    \n",
    "    mean_acc[n-1] = metrics.accuracy_score(y_val, yhat)\n",
    "    print('when kernal is: ',Kernals[n-1],'accuracy = ',mean_acc[n-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Question 5</b> Train a logistic regression model and determine the accuracy of the validation data (set C=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Question 5 - Answers\n",
    "Model is trained below and accuracy is reported.  Tried both liblinear and sag solvers.\n",
    "\n",
    "classification report is created that gives precision, recall, f1score and average accuracy\n",
    "For the case of teams making it into the final 4 (F4),values are reported below\n",
    "\n",
    "y       Precision Recall.   f1-score\n",
    "\n",
    "1       0.50           1.00      0.67\n",
    "\n",
    "1       0.50           1.00      0.67       \n",
    "\n",
    "Logloss value is 0.65 for liblinear solver vs 0.35 for sag. Hence Sag solver is recommended for further use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when solver is:  liblinear accuracy =  0.5833333333333334\n",
      "when solver is:  sag accuracy =  0.5833333333333334\n",
      "when solver is:  saga accuracy =  0.5833333333333334\n",
      "when solver is:  lbfgs accuracy =  0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "solvers=['liblinear', 'sag', 'saga', 'lbfgs']\n",
    "Ks = 5\n",
    "mean_acc = np.zeros((Ks-1))\n",
    "\n",
    "\n",
    "for n in range(1,Ks):\n",
    "    \n",
    "    #Train Model and Predict  \n",
    "    LR = LogisticRegression(C=0.01, solver=solvers[n-1])\n",
    "    LR.fit(X_train, y_train)\n",
    "\n",
    "    yhat = LR.predict(X_val)\n",
    "    \n",
    "    mean_acc[n-1] = metrics.accuracy_score(y_val, yhat)\n",
    "    print('when solver is: ',solvers[n-1],'accuracy = ',mean_acc[n-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation using Test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "# for f1_score please set the average parameter to 'micro'\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_index(predictions, true):\n",
    "    if (len(predictions) == len(true)):\n",
    "        intersect = 0;\n",
    "        for x,y in zip(predictions, true):\n",
    "            if (x == y):\n",
    "                intersect += 1\n",
    "        return intersect / (len(predictions) + len(true) - intersect)\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Question  5</b> Calculate the  F1 score and Jaccard score for each model from above. Use the Hyperparameter that performed best on the validation data. **For f1_score please set the average parameter to 'micro'.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Load Test set for evaluation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEAM</th>\n",
       "      <th>CONF</th>\n",
       "      <th>G</th>\n",
       "      <th>W</th>\n",
       "      <th>ADJOE</th>\n",
       "      <th>ADJDE</th>\n",
       "      <th>BARTHAG</th>\n",
       "      <th>EFG_O</th>\n",
       "      <th>EFG_D</th>\n",
       "      <th>TOR</th>\n",
       "      <th>...</th>\n",
       "      <th>FTRD</th>\n",
       "      <th>2P_O</th>\n",
       "      <th>2P_D</th>\n",
       "      <th>3P_O</th>\n",
       "      <th>3P_D</th>\n",
       "      <th>ADJ_T</th>\n",
       "      <th>WAB</th>\n",
       "      <th>POSTSEASON</th>\n",
       "      <th>SEED</th>\n",
       "      <th>YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>North Carolina</td>\n",
       "      <td>ACC</td>\n",
       "      <td>40</td>\n",
       "      <td>33</td>\n",
       "      <td>123.3</td>\n",
       "      <td>94.9</td>\n",
       "      <td>0.9531</td>\n",
       "      <td>52.6</td>\n",
       "      <td>48.1</td>\n",
       "      <td>15.4</td>\n",
       "      <td>...</td>\n",
       "      <td>30.4</td>\n",
       "      <td>53.9</td>\n",
       "      <td>44.6</td>\n",
       "      <td>32.7</td>\n",
       "      <td>36.2</td>\n",
       "      <td>71.7</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2ND</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Villanova</td>\n",
       "      <td>BE</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>123.1</td>\n",
       "      <td>90.9</td>\n",
       "      <td>0.9703</td>\n",
       "      <td>56.1</td>\n",
       "      <td>46.7</td>\n",
       "      <td>16.3</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>57.4</td>\n",
       "      <td>44.1</td>\n",
       "      <td>36.2</td>\n",
       "      <td>33.9</td>\n",
       "      <td>66.7</td>\n",
       "      <td>8.9</td>\n",
       "      <td>Champions</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Notre Dame</td>\n",
       "      <td>ACC</td>\n",
       "      <td>36</td>\n",
       "      <td>24</td>\n",
       "      <td>118.3</td>\n",
       "      <td>103.3</td>\n",
       "      <td>0.8269</td>\n",
       "      <td>54.0</td>\n",
       "      <td>49.5</td>\n",
       "      <td>15.3</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>52.9</td>\n",
       "      <td>46.5</td>\n",
       "      <td>37.4</td>\n",
       "      <td>36.9</td>\n",
       "      <td>65.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>E8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>ACC</td>\n",
       "      <td>37</td>\n",
       "      <td>29</td>\n",
       "      <td>119.9</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>54.8</td>\n",
       "      <td>48.4</td>\n",
       "      <td>15.1</td>\n",
       "      <td>...</td>\n",
       "      <td>33.4</td>\n",
       "      <td>52.6</td>\n",
       "      <td>46.3</td>\n",
       "      <td>40.3</td>\n",
       "      <td>34.7</td>\n",
       "      <td>61.9</td>\n",
       "      <td>8.6</td>\n",
       "      <td>E8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>B12</td>\n",
       "      <td>37</td>\n",
       "      <td>32</td>\n",
       "      <td>120.9</td>\n",
       "      <td>90.4</td>\n",
       "      <td>0.9662</td>\n",
       "      <td>55.7</td>\n",
       "      <td>45.1</td>\n",
       "      <td>17.8</td>\n",
       "      <td>...</td>\n",
       "      <td>37.3</td>\n",
       "      <td>52.7</td>\n",
       "      <td>43.4</td>\n",
       "      <td>41.3</td>\n",
       "      <td>32.5</td>\n",
       "      <td>70.1</td>\n",
       "      <td>11.6</td>\n",
       "      <td>E8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             TEAM CONF   G   W  ADJOE  ADJDE  BARTHAG  EFG_O  EFG_D   TOR  \\\n",
       "0  North Carolina  ACC  40  33  123.3   94.9   0.9531   52.6   48.1  15.4   \n",
       "1       Villanova   BE  40  35  123.1   90.9   0.9703   56.1   46.7  16.3   \n",
       "2      Notre Dame  ACC  36  24  118.3  103.3   0.8269   54.0   49.5  15.3   \n",
       "3        Virginia  ACC  37  29  119.9   91.0   0.9600   54.8   48.4  15.1   \n",
       "4          Kansas  B12  37  32  120.9   90.4   0.9662   55.7   45.1  17.8   \n",
       "\n",
       "   ...  FTRD  2P_O  2P_D  3P_O  3P_D  ADJ_T   WAB  POSTSEASON  SEED  YEAR  \n",
       "0  ...  30.4  53.9  44.6  32.7  36.2   71.7   8.6         2ND   1.0  2016  \n",
       "1  ...  30.0  57.4  44.1  36.2  33.9   66.7   8.9   Champions   2.0  2016  \n",
       "2  ...  26.0  52.9  46.5  37.4  36.9   65.5   2.3          E8   6.0  2016  \n",
       "3  ...  33.4  52.6  46.3  40.3  34.7   61.9   8.6          E8   1.0  2016  \n",
       "4  ...  37.3  52.7  43.4  41.3  32.5   70.1  11.6          E8   1.0  2016  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_df = pd.read_csv('https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0120ENv3/Dataset/ML0101EN_EDX_skill_up/basketball_train.csv',error_bad_lines=False)\n",
    "test_df = pd.read_csv('https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0120ENv3/Dataset/ML0101EN_EDX_skill_up/basketball_train.csv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.08074446e-01, -1.10135297e+00,  3.37365934e-01,\n",
       "         2.66479976e+00, -2.46831661e+00,  2.13703245e-01,\n",
       "         9.44090550e-01, -1.19216365e+00, -1.64348924e+00,\n",
       "         1.45405982e-02,  1.29523097e+00, -6.23533182e-01,\n",
       "        -9.31788560e-01,  1.42784371e-01,  1.68876201e-01,\n",
       "         2.84500844e-01,  1.62625961e+00, -8.36649260e-01,\n",
       "        -9.98500539e-01,  4.84319174e-01, -6.77003200e-01],\n",
       "       [ 3.63958290e-01,  3.26326807e-01,  7.03145068e-01,\n",
       "        -7.13778644e-01,  1.07370841e+00,  4.82633172e-01,\n",
       "         4.77498943e-01, -1.32975879e+00, -6.86193316e-02,\n",
       "        -7.35448152e-01, -1.35447914e+00, -8.06829025e-01,\n",
       "         3.41737757e-01,  4.96641291e-02,  9.40576311e-02,\n",
       "         1.37214061e+00,  6.93854620e-01, -2.00860931e+00,\n",
       "         9.80549967e-01, -1.19401460e+00,  1.47709789e+00],\n",
       "       [ 3.63958290e-01,  1.18293467e+00,  9.31757027e-01,\n",
       "        -8.78587347e-01,  1.23870131e+00,  7.85179340e-01,\n",
       "        -9.22275877e-01,  5.27775662e-01, -1.86734575e-01,\n",
       "        -1.19385964e-01, -3.17636057e-01,  6.82449703e-01,\n",
       "         1.01292055e+00,  8.07042098e-02, -9.90811637e-01,\n",
       "         1.74718880e+00, -2.38550367e-01,  6.60855252e-01,\n",
       "         1.92295497e+00, -1.19401460e+00,  1.47709789e+00],\n",
       "       [ 3.63958290e-01,  6.11862762e-01,  3.60227129e-01,\n",
       "         7.14563447e-01, -8.92254236e-02, -3.57772849e-01,\n",
       "         6.89586037e-01, -6.41783067e-01,  4.82585136e-01,\n",
       "         3.89534973e-01,  6.80805434e-01,  1.07195337e+00,\n",
       "         1.00800346e-01,  4.96641291e-02,  1.92390609e-02,\n",
       "        -8.40643737e-01,  1.32958529e+00,  3.02756347e-01,\n",
       "         3.83693465e-01, -1.19401460e+00, -6.77003200e-01],\n",
       "       [ 3.63958290e-01, -1.38688893e+00, -1.12575060e+00,\n",
       "         3.92401673e-04, -9.03545224e-01, -1.13094639e+00,\n",
       "         1.09073363e-02,  7.34168378e-01,  5.61328631e-01,\n",
       "         2.28823098e-01,  2.52408203e+00, -5.07336709e-02,\n",
       "        -5.87592258e-01, -1.62650023e+00,  7.67424763e-01,\n",
       "        -2.40566627e-01, -1.00142717e+00, -8.36649260e-01,\n",
       "        -1.81525154e+00,  1.82698619e+00, -6.77003200e-01]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['windex'] = np.where(test_df.WAB > 7, 'True', 'False')\n",
    "test_df1 = test_df[test_df['POSTSEASON'].str.contains('F4|S16|E8', na=False)]\n",
    "test_Feature = test_df1[['G', 'W', 'ADJOE', 'ADJDE', 'BARTHAG', 'EFG_O', 'EFG_D',\n",
    "       'TOR', 'TORD', 'ORB', 'DRB', 'FTR', 'FTRD', '2P_O', '2P_D', '3P_O',\n",
    "       '3P_D', 'ADJ_T', 'WAB', 'SEED', 'windex']]\n",
    "test_Feature['windex'].replace(to_replace=['False','True'], value=[0,1],inplace=True)\n",
    "test_X=test_Feature\n",
    "test_X= preprocessing.StandardScaler().fit(test_X).transform(test_X)\n",
    "test_X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['E8', 'E8', 'E8', 'E8', 'F4'], dtype=object), array([0, 0, 0, 0, 1]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y = test_df1['POSTSEASON'].values\n",
    "test_y[0:5]\n",
    "# y_v = np.where(test_y == 'F4', 1, 0)\n",
    "test_yb = np.where(test_y == 'F4', 1, 0)\n",
    "test_y[0:5],test_yb[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y.shape,test_X.shape,test_yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "Report_data = pd.DataFrame(columns=['Algorithm','Accuracy','Jaccard','F1-score','LogLoss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Jaccard</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Algorithm  Accuracy   Jaccard  F1-score LogLoss\n",
       "0       KNN  0.628571  0.458333  0.628571      NA"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors = 5).fit(X_train,y_train) #training with the final parameters\n",
    "yhat=neigh.predict(test_X)\n",
    "mean_acc = metrics.accuracy_score(test_y, yhat)\n",
    "\n",
    "f1score=metrics.f1_score(test_y, yhat,average='micro')\n",
    "jaccard=jaccard_index(yhat, test_y)\n",
    "LogLoss='NA'\n",
    "Report_data = Report_data._append({\"Algorithm\":'KNN', \"Accuracy\":mean_acc,\"Jaccard\":jaccard, \"F1-score\":f1score,\"LogLoss\":LogLoss}, ignore_index=True)\n",
    "Report_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Jaccard</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Algorithm  Accuracy   Jaccard  F1-score LogLoss\n",
       "0            KNN  0.628571  0.458333  0.628571      NA\n",
       "1  Decision Tree  0.642857  0.473684  0.642857      NA"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 1).fit(X_train,y_train)\n",
    "yhat=dtree.predict(test_X)\n",
    "mean_acc = metrics.accuracy_score(test_y, yhat)\n",
    "f1score=metrics.f1_score(test_y, yhat,average='micro')\n",
    "jaccard=jaccard_index(yhat, test_y)\n",
    "LogLoss='NA'\n",
    "Report_data = Report_data._append({\"Algorithm\":'Decision Tree', \"Accuracy\":mean_acc,\"Jaccard\":jaccard, \"F1-score\":f1score,\"LogLoss\":LogLoss}, ignore_index=True)\n",
    "Report_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Jaccard</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Algorithm  Accuracy   Jaccard  F1-score LogLoss\n",
       "0            KNN  0.628571  0.458333  0.628571      NA\n",
       "1  Decision Tree  0.642857  0.473684  0.642857      NA\n",
       "2            SVM  0.685714  0.521739  0.685714      NA"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='poly')\n",
    "clf.fit(X_train, y_train) #y_t is y_train transformed earlier to binary as above\n",
    "yhat = clf.predict(test_X)\n",
    "\n",
    "mean_acc = metrics.accuracy_score(test_y, yhat)\n",
    "f1score=metrics.f1_score(test_y, yhat,average='micro')\n",
    "jaccard=jaccard_index(yhat, test_y)\n",
    "LogLoss='NA'\n",
    "Report_data = Report_data._append({\"Algorithm\":'SVM', \"Accuracy\":mean_acc,\"Jaccard\":jaccard, \"F1-score\":f1score,\"LogLoss\":LogLoss}, ignore_index=True)\n",
    "Report_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Jaccard</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>1.037187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Algorithm  Accuracy   Jaccard  F1-score   LogLoss\n",
       "0                 KNN  0.628571  0.458333  0.628571        NA\n",
       "1       Decision Tree  0.642857  0.473684  0.642857        NA\n",
       "2                 SVM  0.685714  0.521739  0.685714        NA\n",
       "3  LogisticRegression  0.685714  0.521739  0.685714  1.037187"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#solver = sag gave a much better logloss value\n",
    "LR = LogisticRegression(C=0.01, solver='liblinear').fit(X_train, y_train)\n",
    "yhat = LR.predict(test_X)\n",
    "\n",
    "yhat_prob = LR.predict_proba(test_X)\n",
    "#yhat_yhat_prob=list(zip(yhat,yhat_prob))\n",
    "\n",
    "mean_acc = metrics.accuracy_score(test_y, yhat)\n",
    "f1score=metrics.f1_score(test_y, yhat,average='micro')\n",
    "jaccard=jaccard_index(yhat, test_y)\n",
    "LogLoss=log_loss(test_y, yhat_prob)\n",
    "\n",
    "Report_data = Report_data._append({\"Algorithm\":'LogisticRegression', \"Accuracy\":mean_acc,\"Jaccard\":jaccard, \"F1-score\":f1score,\"LogLoss\":LogLoss}, ignore_index=True)\n",
    "Report_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report\n",
    "You should be able to report the accuracy of the built model using different evaluation metrics:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Algorithm          | Accuracy | Jaccard  | F1-score  | LogLoss |\n",
    "|--------------------|----------|----------|-----------|---------|\n",
    "| KNN                |     ?    |     ?    |     ?     | NA      |\n",
    "| Decision Tree      |     ?    |     ?    |     ?     | NA      |\n",
    "| SVM                |     ?    |     ?    |     ?     | NA      |\n",
    "| LogisticRegression |     ?    |     ?    |     ?     |     ?   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something to keep in mind when creating models to predict the results of basketball tournaments or sports in general is that is quite hard due to so many factors influencing the game. Even in sports betting an accuracy of 55% and over is considered good as it indicates profits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<h2>Want to learn more?</h2>\n",
    "\n",
    "IBM SPSS Modeler is a comprehensive analytics platform that has many machine learning algorithms. It has been designed to bring predictive intelligence to decisions made by individuals, by groups, by systems â€“ by your enterprise as a whole. A free trial is available through this course, available here: <a href=\"https://www.ibm.com/analytics/spss-statistics-software?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork1047-2023-01-01\">SPSS Modeler</a>\n",
    "\n",
    "Also, you can use Watson Studio to run these notebooks faster with bigger datasets. Watson Studio is IBM's leading cloud solution for data scientists, built by data scientists. With Jupyter notebooks, RStudio, Apache Spark and popular libraries pre-packaged in the cloud, Watson Studio enables data scientists to collaborate on their projects without having to install anything. Join the fast-growing community of Watson Studio users today with a free account at <a href=\"https://www.ibm.com/cloud/watson-studio?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork1047-2023-01-01\">Watson Studio</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thank you for completing this lab!\n",
    "\n",
    "\n",
    "## Author\n",
    "\n",
    "Saeed Aghabozorgi\n",
    "\n",
    "\n",
    "### Other Contributors\n",
    "\n",
    "<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkML0101ENSkillsNetwork1047-2023-01-01\">Joseph Santarcangelo</a>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Change Log\n",
    "\n",
    "\n",
    "|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n",
    "|---|---|---|---|\n",
    "|2021-04-03   | 2.1  | Malika Singla| Updated the Report accuracy |\n",
    "| 2020-08-27  | 2.0  | Lavanya  |  Moved lab to course repo in GitLab |\n",
    "|   |   |   |   |\n",
    "|   |   |   |   |\n",
    "\n",
    "\n",
    "## <h3 align=\"center\"> Â© IBM Corporation 2020. All rights reserved. <h3/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
